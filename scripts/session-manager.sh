#!/bin/bash
# Session Manager - PostgreSQL + Redis ä¼šè¯ç®¡ç†ç³»ç»Ÿ
# ç”¨é€”: å½’æ¡£ã€æ¸…ç†ã€ä¿®å¤ OpenClaw ä¼šè¯

set -e

SESSIONS_DIR="$HOME/.openclaw/agents/main/sessions"
BACKUP_DIR="$SESSIONS_DIR/archive"
PG_DB="openclaw"
PG_USER="openclaw"
PG_PASS="openclaw123"
REDIS_PREFIX="openclaw:session"

# é¢œè‰²
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

log() { echo -e "${GREEN}[$(date +%H:%M:%S)]${NC} $1"; }
warn() { echo -e "${YELLOW}[$(date +%H:%M:%S)] WARN:${NC} $1"; }
error() { echo -e "${RED}[$(date +%H:%M:%S)] ERROR:${NC} $1"; }

# åˆå§‹åŒ– PostgreSQL è¡¨
init_db() {
    log "åˆå§‹åŒ– PostgreSQL ä¼šè¯è¡¨..."
    PGPASSWORD=$PG_PASS psql -h localhost -U $PG_USER -d $PG_DB << 'SQL'
-- ä¼šè¯å½’æ¡£è¡¨
CREATE TABLE IF NOT EXISTS session_archive (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(64) NOT NULL,
    session_key VARCHAR(256),
    session_type VARCHAR(32),  -- main, cron, spawn
    created_at TIMESTAMP DEFAULT NOW(),
    archived_at TIMESTAMP DEFAULT NOW(),
    message_count INT DEFAULT 0,
    total_tokens INT DEFAULT 0,
    file_size_bytes INT DEFAULT 0,
    content JSONB,  -- å‹ç¼©åçš„ä¼šè¯å†…å®¹
    raw_file TEXT,  -- åŸå§‹ jsonl å†…å®¹ (å¯é€‰)
    metadata JSONB,
    UNIQUE(session_id)
);

-- ä¼šè¯å¥åº·çŠ¶æ€è¡¨
CREATE TABLE IF NOT EXISTS session_health (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(64) NOT NULL,
    checked_at TIMESTAMP DEFAULT NOW(),
    is_valid BOOLEAN DEFAULT true,
    error_type VARCHAR(64),
    error_message TEXT,
    auto_fixed BOOLEAN DEFAULT false,
    UNIQUE(session_id, checked_at)
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_session_archive_key ON session_archive(session_key);
CREATE INDEX IF NOT EXISTS idx_session_archive_type ON session_archive(session_type);
CREATE INDEX IF NOT EXISTS idx_session_archive_created ON session_archive(created_at);
CREATE INDEX IF NOT EXISTS idx_session_health_valid ON session_health(is_valid);

SELECT 'Tables created successfully' as status;
SQL
    log "æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ"
}

# æ£€æŸ¥ä¼šè¯æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
validate_session() {
    local file="$1"
    local session_id=$(basename "$file" .jsonl)
    
    # åŸºæœ¬ JSON éªŒè¯
    if ! head -1 "$file" | python3 -c "import json,sys; json.load(sys.stdin)" 2>/dev/null; then
        echo "invalid_json"
        return
    fi
    
    # æ£€æŸ¥æ¶ˆæ¯æ ¼å¼ (ç®€åŒ–æ£€æŸ¥)
    local has_invalid=$(python3 << PYEOF
import json
import sys

try:
    with open("$file", 'r') as f:
        for line in f:
            if not line.strip():
                continue
            data = json.loads(line)
            # æ£€æŸ¥ assistant æ¶ˆæ¯çš„ content æ ¼å¼
            if data.get('type') == 'message' and data.get('role') == 'assistant':
                content = data.get('content', [])
                if isinstance(content, list):
                    for item in content:
                        if isinstance(item, dict):
                            # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å¿…éœ€å­—æ®µ
                            if 'type' not in item:
                                print('missing_type')
                                sys.exit(0)
    print('valid')
except Exception as e:
    print(f'error:{e}')
PYEOF
)
    echo "$has_invalid"
}

# å½’æ¡£ä¼šè¯åˆ° PostgreSQL
archive_session() {
    local file="$1"
    local session_id=$(basename "$file" .jsonl)
    local file_size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file")
    local msg_count=$(wc -l < "$file")
    
    log "å½’æ¡£ä¼šè¯: $session_id"
    
    # æå–ä¼šè¯å…ƒæ•°æ®
    local metadata=$(head -1 "$file" | python3 -c "
import json, sys
data = json.load(sys.stdin)
print(json.dumps({
    'version': data.get('version'),
    'cwd': data.get('cwd'),
    'timestamp': data.get('timestamp')
}))
" 2>/dev/null || echo '{}')
    
    # å‹ç¼©å†…å®¹å­˜å…¥æ•°æ®åº“
    local content=$(cat "$file" | gzip | base64 -w0)
    
    PGPASSWORD=$PG_PASS psql -h localhost -U $PG_USER -d $PG_DB -c "
INSERT INTO session_archive (session_id, message_count, file_size_bytes, metadata, raw_file)
VALUES ('$session_id', $msg_count, $file_size, '$metadata'::jsonb, '$content')
ON CONFLICT (session_id) DO UPDATE SET
    archived_at = NOW(),
    message_count = $msg_count,
    file_size_bytes = $file_size;
" 2>/dev/null
    
    echo "$session_id"
}

# æ¸…ç†æ—§çš„ cron ä¼šè¯
cleanup_cron_sessions() {
    local days_old=${1:-3}
    log "æ¸…ç† ${days_old} å¤©å‰çš„ cron ä¼šè¯..."
    
    mkdir -p "$BACKUP_DIR"
    
    local count=0
    cd "$SESSIONS_DIR"
    
    # æ‰¾åˆ°æ—§çš„ cron ä¼šè¯
    for file in *.jsonl; do
        [[ -f "$file" ]] || continue
        
        # æ£€æŸ¥æ–‡ä»¶å¹´é¾„
        local file_age=$(( ($(date +%s) - $(stat -c%Y "$file" 2>/dev/null || stat -f%m "$file")) / 86400 ))
        
        if [[ $file_age -ge $days_old ]]; then
            local session_id=$(basename "$file" .jsonl)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ cron ä¼šè¯ (ä¸æ˜¯ main)
            if grep -q "cron" "$SESSIONS_DIR/../sessions.json" 2>/dev/null | grep -q "$session_id"; then
                # å½’æ¡£åˆ°æ•°æ®åº“
                archive_session "$file"
                
                # ç§»åŠ¨åˆ°å¤‡ä»½ç›®å½•
                mv "$file" "$BACKUP_DIR/"
                ((count++))
            fi
        fi
    done
    
    log "æ¸…ç†å®Œæˆ: å½’æ¡£äº† $count ä¸ªä¼šè¯"
}

# ä¿®å¤æŸåçš„ä¼šè¯
fix_corrupted_sessions() {
    log "æ‰«æå¹¶ä¿®å¤æŸåçš„ä¼šè¯..."
    
    mkdir -p "$BACKUP_DIR/corrupted"
    
    local fixed=0
    local removed=0
    
    cd "$SESSIONS_DIR"
    for file in *.jsonl; do
        [[ -f "$file" ]] || continue
        
        local status=$(validate_session "$file")
        local session_id=$(basename "$file" .jsonl)
        
        if [[ "$status" != "valid" ]]; then
            warn "å‘ç°æŸåä¼šè¯: $session_id ($status)"
            
            # è®°å½•åˆ°æ•°æ®åº“
            PGPASSWORD=$PG_PASS psql -h localhost -U $PG_USER -d $PG_DB -c "
INSERT INTO session_health (session_id, is_valid, error_type, error_message)
VALUES ('$session_id', false, '$status', 'Auto-detected corruption')
ON CONFLICT DO NOTHING;
" 2>/dev/null
            
            # å½’æ¡£ååˆ é™¤
            archive_session "$file"
            mv "$file" "$BACKUP_DIR/corrupted/"
            ((removed++))
        fi
    done
    
    log "ä¿®å¤å®Œæˆ: ç§»é™¤äº† $removed ä¸ªæŸåä¼šè¯"
    
    # æ›´æ–° Redis çŠ¶æ€
    redis-cli SET "${REDIS_PREFIX}:last_cleanup" "$(date +%s)" > /dev/null
    redis-cli SET "${REDIS_PREFIX}:corrupted_count" "$removed" > /dev/null
}

# ä» sessions.json ä¸­ç§»é™¤æ— æ•ˆä¼šè¯
sync_sessions_json() {
    log "åŒæ­¥ sessions.json..."
    
    cd "$SESSIONS_DIR"
    
    python3 << 'PYEOF'
import json
import os

sessions_file = 'sessions.json'
backup_file = 'sessions.json.bak'

# å¤‡ä»½
import shutil
shutil.copy(sessions_file, backup_file)

with open(sessions_file, 'r') as f:
    data = json.load(f)

# è·å–æ‰€æœ‰å­˜åœ¨çš„ session æ–‡ä»¶
existing_files = set(f.replace('.jsonl', '') for f in os.listdir('.') if f.endswith('.jsonl'))

# è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„ä¼šè¯
removed = []
for key in list(data.keys()):
    if isinstance(data[key], dict):
        session_id = data[key].get('sessionId')
        if session_id and session_id not in existing_files:
            removed.append(key)
            del data[key]

if removed:
    with open(sessions_file, 'w') as f:
        json.dump(data, f, indent=2)
    print(f"ç§»é™¤äº† {len(removed)} ä¸ªæ— æ•ˆä¼šè¯å¼•ç”¨")
else:
    print("sessions.json å·²åŒæ­¥")
PYEOF
}

# çŠ¶æ€æŠ¥å‘Š
status() {
    echo "=== Session Manager çŠ¶æ€ ==="
    echo ""
    
    # æ–‡ä»¶ç»Ÿè®¡
    local total_files=$(ls -1 "$SESSIONS_DIR"/*.jsonl 2>/dev/null | wc -l)
    local total_size=$(du -sh "$SESSIONS_DIR" 2>/dev/null | cut -f1)
    local archived=$(ls -1 "$BACKUP_DIR"/*.jsonl 2>/dev/null | wc -l)
    
    echo "ğŸ“ ä¼šè¯æ–‡ä»¶: $total_files ä¸ª ($total_size)"
    echo "ğŸ“¦ å·²å½’æ¡£: $archived ä¸ª"
    
    # æ•°æ®åº“ç»Ÿè®¡
    local db_count=$(PGPASSWORD=$PG_PASS psql -h localhost -U $PG_USER -d $PG_DB -t -c "SELECT COUNT(*) FROM session_archive;" 2>/dev/null | tr -d ' ')
    local corrupted=$(PGPASSWORD=$PG_PASS psql -h localhost -U $PG_USER -d $PG_DB -t -c "SELECT COUNT(*) FROM session_health WHERE is_valid = false;" 2>/dev/null | tr -d ' ')
    
    echo "ğŸ—„ï¸  æ•°æ®åº“å½’æ¡£: ${db_count:-0} ä¸ª"
    echo "âš ï¸  å†å²æŸå: ${corrupted:-0} ä¸ª"
    
    # Redis çŠ¶æ€
    local last_cleanup=$(redis-cli GET "${REDIS_PREFIX}:last_cleanup" 2>/dev/null)
    if [[ -n "$last_cleanup" ]]; then
        local cleanup_date=$(date -d "@$last_cleanup" "+%Y-%m-%d %H:%M" 2>/dev/null || date -r "$last_cleanup" "+%Y-%m-%d %H:%M")
        echo "ğŸ• ä¸Šæ¬¡æ¸…ç†: $cleanup_date"
    fi
    
    echo ""
}

# ä¸»å‘½ä»¤
case "${1:-status}" in
    init)
        init_db
        ;;
    cleanup)
        cleanup_cron_sessions "${2:-3}"
        sync_sessions_json
        ;;
    fix)
        fix_corrupted_sessions
        sync_sessions_json
        ;;
    archive)
        if [[ -n "$2" ]]; then
            archive_session "$SESSIONS_DIR/$2.jsonl"
        else
            error "è¯·æŒ‡å®š session_id"
        fi
        ;;
    sync)
        sync_sessions_json
        ;;
    status)
        status
        ;;
    *)
        echo "ç”¨æ³•: $0 {init|cleanup|fix|archive|sync|status}"
        echo ""
        echo "å‘½ä»¤:"
        echo "  init     - åˆå§‹åŒ–æ•°æ®åº“è¡¨"
        echo "  cleanup  - æ¸…ç†æ—§çš„ cron ä¼šè¯ (é»˜è®¤3å¤©)"
        echo "  fix      - ä¿®å¤æŸåçš„ä¼šè¯"
        echo "  archive  - å½’æ¡£æŒ‡å®šä¼šè¯"
        echo "  sync     - åŒæ­¥ sessions.json"
        echo "  status   - æ˜¾ç¤ºçŠ¶æ€"
        ;;
esac
